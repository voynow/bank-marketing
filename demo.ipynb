{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection, according to .txt info\n",
    "1. duration is removed: \"should be discarded if the intention is to have a realistic predictive model\"\n",
    "2. pdays is removed: This attribute is highly skewed being that pdays=999 when client has not been previously contacted. For the purpose of this project, this attribute will be discarded. \n",
    "\n",
    "Expanding on pdays: For future work, this attribute could be used to create a new feature (contacted (1) VS not contacted (0), or a categorical binning of the pdays values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = [\"campaign\", \"previous\", \"age\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"]\n",
    "CATEGORICAL_FEATURES = [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"poutcome\", \"loan\", \"contact\", \"month\", \"day_of_week\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "1. Read CSVs extracting features and targets from each, where the target column is mapped to binary values\n",
    "2. Convert categorical features to numerical using OneHotEncoding\n",
    "3. Scale numerical features using StandardScaler, a popular alternative is MinMaxScaler\n",
    "\n",
    "Future work: With more data analysis (correlation, feature importance, etc.), we can choose features more wisely. Similarly, looking closer into the data distributions, we can scale the numerical features more appropriately (MinMaxScaler VS StandardScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load data & split features VS target\"\"\"\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    target = df[\"y\"].map({\"yes\": 1, \"no\": 0})\n",
    "    features = df.drop(\"y\", axis=1)\n",
    "    return features, target\n",
    "\n",
    "\n",
    "def transform_features(\n",
    "    train: pd.DataFrame, test: pd.DataFrame\n",
    ") -> Tuple[scipy.sparse.csr_matrix, scipy.sparse.csr_matrix]:\n",
    "    \"\"\"Transform features into a format suitable for training\"\"\"\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder())])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, NUMERICAL_FEATURES),\n",
    "            ('cat', categorical_transformer, CATEGORICAL_FEATURES),\n",
    "        ]\n",
    "    )\n",
    "    return preprocessor.fit_transform(train), preprocessor.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "1. Choosing three relatively simple models to start with: Logistic Regression, K-Nearest Neighbors, and Random Forest\n",
    "2. Initializing each with arbitrary hyperparameters, ensuring that they train in a reasonable amount of time\n",
    "3. Once each model is trained, we can evaluate their performance on the holdout set using classification_report\n",
    "\n",
    "Further work: We can use GridSearchCV/RandomSearchCV to find the best hyperparameters for each model. Additionally, there is much more model exploration to be done outside of our three initial candidates (e.g. Ensemble methods, Deep Learning, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_pipeline(\n",
    "    x_train: scipy.sparse.csr_matrix, \n",
    "    x_test: scipy.sparse.csr_matrix, \n",
    "    y_train: np.array, \n",
    "    y_test: np.array,\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Train models and return classification_report for each\"\"\"\n",
    "    models = {\n",
    "        'LR': LogisticRegression(),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "        'RF': RandomForestClassifier(n_estimators=25)\n",
    "    }\n",
    "    performance = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        strt = time.time()\n",
    "        print(f\"Training {name}...\")\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        performance[name] = classification_report(y_test, y_pred)\n",
    "        print(f\"{name} traing done in {time.time() - strt:.2f}s\")\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR...\n",
      "LR traing done in 0.07s\n",
      "Training KNN...\n",
      "KNN traing done in 5.30s\n",
      "Training RF...\n",
      "RF traing done in 4.99s\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"data/bank-additional/\"\n",
    "\n",
    "# pull in data\n",
    "x_train, y_train = read_data(base_dir + \"bank-additional-full.csv\")\n",
    "x_test, y_test = read_data(base_dir + \"bank-additional.csv\")\n",
    "\n",
    "# prep for training\n",
    "x_train, x_test = transform_features(x_train, x_test)\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# train models\n",
    "performance = run_training_pipeline(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      3668\n",
      "           1       0.64      0.24      0.35       451\n",
      "\n",
      "    accuracy                           0.90      4119\n",
      "   macro avg       0.78      0.61      0.65      4119\n",
      "weighted avg       0.88      0.90      0.88      4119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logist regression does well on the majority class (class=0) but not so well on the minority class (class=1)\n",
    "\n",
    "print(performance['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3668\n",
      "           1       0.76      0.50      0.60       451\n",
      "\n",
      "    accuracy                           0.93      4119\n",
      "   macro avg       0.85      0.74      0.78      4119\n",
      "weighted avg       0.92      0.93      0.92      4119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN Follows a similar pattern as logistic regression, but performs slightly better on the minority class\n",
    "\n",
    "print(performance['KNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3668\n",
      "           1       0.98      0.92      0.95       451\n",
      "\n",
      "    accuracy                           0.99      4119\n",
      "   macro avg       0.98      0.96      0.97      4119\n",
      "weighted avg       0.99      0.99      0.99      4119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest performs well on both classes, almost surprisingly well!\n",
    "\n",
    "print(performance['RF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up\n",
    "As a final note, we see that the random forest performs much better than the other two models. All models performed well on the majority class, but the random forest was the only one to perform well on the minority class as well.\n",
    "\n",
    "Future work: Along with all other future work mentioned above, we could possibly investigate the use of  or other techniques to balance the classes. Although, it is important to note that the random forest model is already performing well on the minority class so this additional work may not be necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
